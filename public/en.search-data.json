{"/docs/":{"data":{"":"","going-deep-with-sres#Going deep with SREs":"I created some how-to guides in FY23 to help customers navigate the platform’s dense UI. Since observability usually means any given user has a large amount of data coming in about their system, I wanted these docs to help users think about the product in a more meaningful way. I kept the story relatively simple for a couple reasons:\nSince the majority of Company’s customers are app developers, I decided a simple story could get them thinking like an SRE, even if that’s not a hat they usually wear. If an SRE used the doc, I suspected they could take this basic framework and complexify it to fit their use cases. These how-to guides gave me plenty of exposure to our field and support teams. While I chatted with product and engineering to get a sense of why they made certain prod decisions, it was important to me that I wrote a story about how our users are actually using the product, rather than how we wanted them to.","learning-about-llms#Learning about LLMs":"The site is hosted on Netlify and built with Hugo using the Hextra theme.\nI’ve curated these docs to capture the four docs types, per Diátaxis: conceptual, procedural, reference, and tutorial. I’ve shortened these docs so they may not reflect the full scope of the live projects.\nAll docs were written in VS Code. I collaborated with stakeholders through GitHub using git version control. I took product screenshots with SnagIt. To avoid any conflicts, I’ve removed the original images and replaced them with something more whimsical. As an additional note, I’ve removed all hyperlinks but kept the Markdown format to give you a sense of when/how I link to other docs. I recommend checking out my GitHub account if you’re curious about how I provide feedback to engineering and product SMEs, or how I might manage sweeping changes to information architecture.\nLearning about LLMs\rIn FY24, I supported a major feature launch that let data scientists and developers monitor their LLM-based apps. Regardless of my personal opinions about GenAI hype, the experience helped me wrestle with technology that had real industry ambiguity. Our user researcher summed it up well: GenAI is an area where practicioners learn as they do the thing. This held true for me, too. I found myself learning alongside my SMEs while my research expanded beyond tech news into the world of academia.\nI ventured lots of guesses about how embedding, tokenization, and various models might work. Those guesses proved to be inelegant at best, but my SMEs were patient and helpful. Together we pushed out a ton of docs about a completely new feature in a completely new tech space.\nI’ve included two docs from this feature release. The first is an introduction doc that covers a mix of observability and AI concepts. The second is an API reference for retrieving certain kinds of LLM data.","untangling-the-aws-story#Untangling the AWS story":"tl;dr: You can collect AWS metrics and store them in Company’s platform by polling individual API endpoints for each AWS service, or by integrating an agent with an AWS service. Company wanted to position the integration as our primary, recommended method.\nThe tricky part is that product still supports the API polling method, so the docs needed to stay live. This resulted in a seemingly random intermixing of procedures across several docs without a clear recommendation about where to start. Docs were littered with callouts for a new integration, but didn’t describe value or who should opt in. The area lacked formal logos despite having a real urgency to use the integration.\nWith this context, I made some decisions:\nI created a single set up doc that functions as a “start here” for anyone wanting AWS data in the platform. The steps are for both first time users and existing users on the polling method. I updated the intro doc with clear messaging about what procedures exist and why you’d choose one over the other. I removed all of those bizarre, billboard-y style callouts about the integration across all docs. I preserved the set up instructions for the API polling method and grouped that doc with other alternative set-up procedures. (tl;dr Amazon is really complex and there were different procedures if you maintain EC2 instances, use their Kubernetes service, or are a GovCloud customer.) This project was ad hoc, ambiguous, and really fun. I learned a lot about AWS and got to do some IA restructuring, which is my favorite kind of docs work."},"title":"Portfolio notes~"},"/docs/ai-monitoring/":{"data":{"":"","compatibility-and-requirements#Compatibility and requirements":"Monitoring for AI is our solution for application monitoring (APM) for LLM-based apps. When you enable monitoring for AI, our agents can give you end-to-end visibility into performance, cost, and quality of your OpenAI or BedRock models. You can explore how users interact with an AI assistant, dig into trace-level details about a model’s response to an AI event, and compare the performance of different models across app environments.\nHow does monitoring for AI work?\rTo get started with monitoring for AI, you’ll instrument your LLM-powered app with one of our APM agents. Once you’ve instrumented your app, you can enable monitoring for AI so the agent can capture LLM observability data.\nWhen your AI assistant receives a prompt and returns a response, the agent captures metric and event data generated from external LLMs and vector stores. Our agent can:\nParse information about completion, prompt, and response tokens Track requests and responses that pass through any of our supported models Correlate negative or positive feedback about a response from your end users You can access all this information and more from the platform, then create alerts and dashboards to help you effectively manage your AI data and improve performance.\nImprove your LLM app performance\rMonitoring for AI can help you answer critical questions about AI app performance: are your end users waiting too long for a response? Is there a recent spike in token usage? Are there patterns of negative user feedback around certain topics? With monitoring for AI, you can see data specific to the AI-layer:\nIdentify errors in specific prompt and response interactions from the response table. If you’re looking to make improvements to your AI models, learn how to analyze your model with trace-level data. If you’re using different models across app environments, you can compare the cost and performance of your apps before deploying. Are you concerned about data compliance? Learn how to create drop filters to drop sensitive data before you send it to the platform. Monitoring for AI allows agents to recognize and capture AI data. Monitoring for AI has different library compatibility requirements depending on what language you used for your LLM-powered app.\nCompatibility and requirements\rMonitoring for AI has different library and compatibility requirements depending on what language you used for your LLM-powered app.\nWhen you disable distributed tracing or enable high security mode, the agent won’t capture AI data. You shouldn’t enable monitoring for AI if you’re a FedRAMP customer, because AI and AI-based technologies are not yet FedRAMP authorized. Compatible AI libraries\rAgent version Supported libraries Go version 3.31.0 and above * Go OpenAI library versions 1.19.4 and above\n* AWS SDK for Go v2 versions 1.6.0 and above Java version 8.12.0 and above * AWS SDK for Java v2 Bedrock Runtime Client versions 2.20.157 and above .NET version 10.23.0 and above * AWS Bedrock version 3.7.200 and above Node.js version 11.13.0 and above * OpenAI Node.js API library versions 4.0.0 and above. If your model uses streaming, the Node.js agent supports versions 4.12.2 and above\n* AWS SDK for JavaScript BedrockRuntime Client versions 3.474.0 and above\n* LangChain.js versions 0.1.17 and above Python version 9.8.0 and above * OpenAI library versions 0.28.0 and above.\n* Boto3 AWS SDK for Python versions 1.28.57 and above.\n* LangChain versions 0.1.0 and above. Ruby version 9.8.0 and above * OpenAI gem version 3.4.0 and above Monitoring at scale with NVIDIA NIM\rMonitoring for AI can integrate with and collect data about any models supported by NVIDIA NIM. For example, if you’ve built a Python or Node.js AI app that uses llama3, mistralai, or one of NVIDIA’s proprietary LLMs, you can instrument those apps with monitoring for AI and view performance data about your apps.\nNo additional steps are needed to integrate with NVIDIA NIM: you can follow our manual procedures for installation, or install directly through the platform.","get-started-with-monitoring-for-ai#Get started with monitoring for AI":"Ready to get started? Make sure to confirm that you can instrument your AI library or framework. You may need to update the agent if you’ve already instrumented your app.\nWhen you’re ready, use our doc to manually install monitoring for . This doc directs you to the relevant procedures for installing an APM agent, then walks you through configuring the agent to capture LLM-specific data.","how-does-monitoring-for-ai-work#How does monitoring for AI work?":"","improve-your-llm-app-performance#Improve your LLM app performance":""},"title":"Intro to monitoring for GenAI"},"/docs/api/":{"data":{"":"","description#Description":"","example-obtain-trace-id-and-record-feedback#Example: Obtain trace ID and record feedback":"Syntax\rfakefunction.record_llm_feedback_event(trace_id, rating, category=None, message=None, metadata=None)\rRecords custom feedback events for GenAI LLMs.\nRequirements\rEnsure you have your API key and you’re using agent version 9.8.0 or higher.\nDescription\rThe agent API can record a feedback event LlmFeedbackMessage that describes whether an end user found an LLM response helpful. The agent API, however, records this data in different places since both events occur in two transactions. This means your function needs to:\nCapture the trace ID that generates with LLM message (fakefunction.agent.current_trace_id()) since the trace ID can connect feedback to LLM rresponse. Pass that trace ID to the endpoint that records the feedback (fakefunction.agent.record_llm_feedback_event()) Parameters\rParameter Description trace_id Required. ID of the trace where the chat completion(s) related to the feedback occurred. This ID can be obtained via a call to current_trace_id. rating Required. Rating provided by an end user (ex: “Good/Bad”, “1-10”). category Optional. Category of the feedback provided by the end user (ex: “informative”, “inaccurate”). message Optional. Freeform text feedback from an end user. metadata Optional. Set of key-value pairs to store any other desired data to submit with the feedback event. Return values\rNone.\nExample: Obtain trace ID and record feedback\rimport fake.agent def get_message(request): trace_id = fakefunction.agent.current_trace_id() def post_feedback(request): fakefunction.agent.record_llm_feedback_event(trace_id=request.trace_id, rating=request.rating, metadata= {\"my_key\": \"my_val\"})","parameters#Parameters":"","requirements#Requirements":"","return-values#Return values":"","syntax#Syntax":""},"title":"API reference `record_llm_feedback_event`"},"/docs/aws/":{"data":{"":"","integrate-cloudwatch-metric-streams-with-the-platform#Integrate CloudWatch Metric Streams with the platform":"","prerequisites#Prerequisites":"","whats-next#What\u0026rsquo;s next?":"You can collect metrics about your AWS services in a CloudWatch repository, then use AWS CloudWatch Metric Streams to direct a real-time stream of metrics to a destination of your choice, like to Company. Integrating AWS with Company lets you view your AWS data alongside your other observability entities, giving you a seamless monitoring experience as you troubleshoot and make improvements to your system environment.\nTo get started, you’ll follow three broad integration steps:\nDefining an HTTP endpoint set to either our US or EU datacenters Creating custom configurations for the kinds of AWS data you want to stream, based on your individual use case Adding your AWS account to your Company account Prerequisites\rBefore you get started, make sure to update the permissions to your AWS roles:\nAt minimum, create a ReadOnlyAccess policy and apply them to your AWS roles associated with your Company account. If you’re managing multiple AWS accounts, make sure you connect all of them to a single Company account. Integrate CloudWatch Metric Streams with the platform\rThese integration procedures use AWS console to complete set up. They assume you’ve created a Kinesis Data Firehose and metric stream in the past, but we’ll provide some external links to AWS docs to help you along the way.\nCreate and configure a Firehose delivery stream\rAWS manages your data streaming with Amazon Data Firehose, which lets you create a separate Kinesis Data Firehose to deliver your AWS metric data. After creating a new Firehose delivery stream, input the following configurations from AWS constole:\nDelivery stream configurations\rDestination parameters:\nSource: Direct PUT or other sources Data transformation: disabled Record format conversion: disabed Destination: Choose Company from the dropdown. Define these Company-specific configurations under Destination settings:\nHTTP endpoint URL - US Datacenter: https://aws-api.THISISFAKE.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.THISISFAKE.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only\nS3 bucket: select a bucket or create a new one to store metrics that failed to be sent.\nApply buffer conditions\nBuffer size: 1MB Buffer interval: 60 (seconds) For the Permissions IAM role, either create or update IAM role for Company.\nIf you manage multiple regions across different AWS accounts, create a separate Kinesis Data Firehose per each region and point them to Company.\nCreate and configure a new metric stream\rYou can think of a metric stream as a post office for your AWS metrics while the Firehose delivery system is the truck that delivers it to yourr destination. This step assigns your Firehose to a newly created metric stream, which ensures your AWS data is delivered to the platform.\nFrom AWS Console, find CloudWatch Service, choose Streams from the Metrics menu, then click Create a metric stream. Configure your metric stream based on your use case. For example, you may opt to use inclusion and exclusion filters to push some AWS service metrics to Platform, but not others. Select the Firehose delivery stream you created in the previous step. We recommend giving it a meaningful name, like our-company-name-metric-stream. Update the default output format to Open Telemetry 0.7. JSON is currently unsupported. Connect AWS and platform\rYou’ve finished the AWS portion of these procedures, so now it’s time to head to the platform. To add your account, go to PLATFORMWEBSITE \u003e TILE NAME HERE \u003e ANOTHER THING TO SELECT \u003e AWS. From the left menu, select Add an AWS account then select Use metric streams. The platform will walk you through the rest!\nValidate your data’s streaming\rWe recommend that you run a simple AWS query using our company’s SQL language. Find our query builder anchored at the bottom of the platform, then run this simple query:\nSELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName\rWhat’s next?\rNow that you’re all set up, we recommend checking out some additional resources:\nCheck out how to create alerts, use tags, and manage your AWS data. Learn how to monitor your EC2 instances or your EKS cluster. Review the mechanics of querying with NRQL to get the most out of your data. "},"title":"Procedure to integrate AWS"},"/docs/infra-monitoring/":{"data":{"":"","make-a-resource-decision-about-an-outage#Make a resource decision about an outage":"","objectives#Objectives":"","whats-next#What\u0026rsquo;s next?":"Your infrastructure requires regular inspection and maintenance. Like a city planner designing a new road or bridge, decisions about what your system needs should come from careful observation about existing limitations. For a tech stack, this looks like a series of resource decisions that you may need to provision to enhance the performance of your apps and services.\nWith our agent, you can collect metrics and event data to help you make resource decisions about your system infrastructure. This doc synthesizes a platform journey for troubleshooting app failure with host data.\nObjectives\rYou will learn to:\nScope your data to help you find root cause Make data-driven resource decisions using your host data The tutorial assumes you’ve already created your first alert.\nMake a resource decision about an outage\rStart with your alerts\rWhen you’re first building out your maintenace workflows, we recommend starting with Summary page overview until you find a better starting point for your unique use case. To start out, we’re going to head on over to PLATFORMWEBSITE \u003e TILE NAME HERE \u003e ANOTHER THING TO SELECT \u003e Infrastructure to view the summary page. This page shows you a lot of aggregated data about your system, but we can break this down into something more manageable.\nWe’ve divided your summary page into three sections:\nA row of four widgets that identify the particulars of your system, like the number of apps serviced by your hosts and how many alerts are notifying you about incidents in your system. A middle section with time series graphs showing you a high level overview of your CPU, memory, and disk resources. A summary table that breaks down these metrics by individual hosts. You might be familiar with our filter bar anchored to the top of all our capability pages. You can use this filter bar to scope the summary page to data about alerting entities. We’ve added this query to the filter bar: alertSeverity = 'CRITICAL'\nFind the failing app\rNotice how this query scoped the entire page from hundreds of hosts to three.\nThe CPU (%) time series indicates that:\napache-svr01 spiked from 15% CPU usage to just over 60% proxy-west-2 mimicked the behavior host-tower-chicago flatlined This isn’t enough information to declare our root cause, but it does limit the range of possibilities for our incident. There are any number of reasons for high CPU, but it’s likely the issue has something to do with either:\nThe app is running a redundant process that’s causing CPU to spike, so the app-owning team needs to optimize some code. More end users are accessing a certain component and adding stress to our system, so we need to provision more resources to meet that load. If we click the applications widget, our summary page opens a relationship modal that shows different apps serviced by various hosts. Note how the Orders team service is both alerting a critical incident and has a relationship to apache-svr01. We can assume that something changed first with Orders team and apache-svr01, which then affected our other two alerting hosts.\nWe can exit the modal and return to the summary page so we can explore the overview page for apache-svr-01.\nDetermine root cause\rSince we’ve identified our fussy app, we can start testing our hypotheses from earlier. At this stage, the goal is to identify any patterns that help us answer the question: is app failure related to inefficient code or stress on the system?\nThe host overview page shows familiar widgets like CPU, memory, and disk usage, but also includes data about network, processes, load, and storage. To the right of the page is a sidebar that shows information about latest events limited to 30 minutes ago, any other related entities, and open issues your team’s created. This isn’t helpful to us right now, but we suspect you’ll encounter situations in the future where it can definitely help you.\nSince we’re disambiguating whether root cause is about app code or resources, we’ll take a quick glance at our Network and Processes widgets. We can see that:\nOur load average time series shows regular intervals for the last hour, but nothing that parallels our CPU % pattern. Network traffic shows regular interviews, but no parallels either. Our running processes show about a dozen different kinds of processes, but there’s a ruby process using 77.34% of your CPU. If load stress affected our CPU %, we’d expect to see a steep spike at the same time our CPU spiked, then a potential flatline when the app failed in the network and load graphs. Since we definitely don’t see that, we have pretty high confidence that the critical incident has to do with some kind of app process, not a resource one.\nSince we don’t need to provision any resources to our host, we can notify the app-owning team that some Ruby process is disrupting their Orders team service.\nℹ️\rIt’s best practice to check your Latest events sidebar to ensure someone hasn’t made direct changes to the machine. Look for any change in the machine’s config file or whether someone has entered the machine to make changes directly.\rWhat’s next?\rSo far we’ve covered how to use infrastructure data to troubleshoot a resource-related incident. We’ve covered how to scope down from thousands of hosts to a set of hosts, then correlated data to make a decision. The next doc shows you how to create custom dashboards using infrastructure metrics."},"title":"Tutorial to resolve app outage with host data"},"/resume/":{"data":{"":"\rPrevious\rNext    \r/ [pdf]\rView the PDF file here."},"title":"resume"}}