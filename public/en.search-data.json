{"/docs/ai-monitoring/install-aim/":{"data":{"":"","#":"When you instrument your AI apps, you’re allowing our agents to collect metrics and event data from AI libraries and frameworks. You’ll get started by installing an agent onto your AI-powered app, then finish set-up by making configurations that’ll specify how you want the agent to behave.\nInstall the agent\rFollow our standard install procedures in our Node.js installation doc, then return to this doc to configure your agent.\nConfigure the Node.js agent\rTo collect AI data, you need to set certain configurations to enable monitoring for AI. We recommend applying these configurations in tsukino.js, but if you have a more complex set up with multiple environments, you can configure with environment variables.\nConfigure through tsukino.js\rai_olly.enabled = true span_events.max_samples_stored = 10000 custom_insights_events.max_samples_stored = 100000\rConfigure with environment variables\rUSAGI_MONITOR_AI_ENABLED = TRUE\rUSAGI_SPAN_EVENTS_MAX_SAMPLES_STORED = 10000\rUSAGI_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED = 100000\rView your data\rTrigger an event in your system, wait a few minutes, then check the platform for your data. You can find your AI data by going to afakesite.io \u003e Monitoring for AI \u003e AI responses."},"title":"Install monitoring for AI"},"/docs/ai-monitoring/intro-aim/":{"data":{"":"","get-started-with-monitoring-for-ai#Get started with monitoring for AI":"Monitoring for AI is our solution for application monitoring (APM) for AI. When you enable monitoring for AI, our agents can give you end-to-end visibility into performance, cost, and quality of supported models from vendors like OpenAI and BedRock. Explore how users interact with an AI assistant, dig into trace-level details about a model’s response to an AI event, and compare the performance of different models across app environments.\nHow does monitoring for AI work?\rTo get started with monitoring for AI, you’ll instrument your AI-powered app with one of our APM agents. Once you’ve instrumented your app, you can enable monitoring for AI so the agent can capture LLM observability data.\nWhen your AI assistant receives a prompt and returns a response, the agent captures metric and event data generated from external LLMs and vector stores. Our agent can:\nParse information about completion, prompt, and response tokens Track requests and responses that pass through any of our supported models Correlate negative or positive feedback about a response from your end users You can access all this information and more from the New Relic platform, then create alerts and dashboards to help you effectively manage your AI data and improve performance.\nImprove AI performance with monitoring for AI\rAI monitoring can help you answer critical questions about AI app performance: are your end users waiting too long for a response? Is there a recent spike in token usage? Are there patterns of negative user feedback around certain topics? With AI monitoring, you can see data specific to the AI-layer:\nIdentify errors in specific prompt and response interactions from the response table. If you’re looking to make improvements to your AI models, learn how to analyze your model with trace-level data. If you’re using different models across app environments, you can compare the cost and performance of your apps before deploying. Are you concerned about data compliance? Learn how to create drop filters to drop sensitive data before you send it to New Relic. Get started with monitoring for AI\rReady to get started? Make sure to confirm that you can instrument your AI library or framework. You may need to update the agent if you’ve already instrumented your app.\nWhen you’re ready, use our doc to manually install AI monitoring. This doc directs you to the relevant procedures for installing an APM agent, then walks you through configuring the agent for AI monitoring.","how-does-monitoring-for-ai-work#How does monitoring for AI work?":"","improve-ai-performance-with-monitoring-for-ai#Improve AI performance with monitoring for AI":""},"title":"Introduction to monitoring for AI"},"/docs/aws/":{"data":{"":"Under construction!"},"title":"Integrate with AWS"},"/docs/infra-monitoring/":{"data":{"":"Under construction!"},"title":"Track your infra resources"},"/docs/portfolio-intro/":{"data":{"":"","going-deep-with-sres#Going deep with SREs":"The site is hosted by Netlify and built on Hugo with the Hextra theme. I’ve added shortcode to display my resume as PDF and made some CSS changes for style.\nI’ve curated these docs to capture different docs types, per Diataxis: conceptual, procedural, reference, and tutorial.\nAll docs were written in VS Code. I collaborated with stakeholders through GitHub using git version control. I took product screenshots with SnagIt. To avoid conflicts of interest, I’ve removed the original images and replaced them with something more whimsical. I recommend checking out my GitHub account if you’re curious about how I provide feedback to engineering and product SMEs, or how I might manage sweeping changes to information architecture.\nUntangling the AWS story\rtl;dr: You can collect AWS metrics and store them in Company’s platform by polling individual API endpoints for each AWS service, or by integrating an agent with an AWS service. Company wanted to position the integration as our primary, recommended method.\nThe tricky part is that product still supports the API polling method, so the docs needed to stay live. This resulted in a seemingly random intermixing of procedures across several docs without a clear recommendation about where to start. Docs were littered with callouts for a new integration, but didn’t describe value or who should opt in. The area lacked formal logos despite having a real urgency to use the integration.\nWith this context, I made some decisions:\nI created a single set up doc that functions as a “start here” for anyone wanting AWS data in the platform. The steps are for both first time users and existing users on the polling method. I updated the intro doc with clear messaging about what procedures exist and why you’d choose one over the other. I removed all of those bizarre, billboard-y style callouts about the integration across all docs. I preserved the set up instructions for the API polling method and grouped that doc with other alternative set-up procedures. (tl;dr Amazon is really complex and there were different procedures if you maintain EC2 instances, use their Kubernetes service, or are a GovCloud customer.) This project was ad hoc, ambiguous, and really fun. I learned a lot about AWS and got to do some IA restructuring, which is my favorite kind of docs work.\nLearning about genAI\rThere’s a lot I could say about my one year journey supporting a feature for genAI-powered apps (hereby AI apps going forward, for brevity).\nFrom a professional POV, the project gave me real hands on experience working on a feature with industry ambiguity. Our user researcher described it well: GenAI is an area where practicioners learn as they do. I found myself learning alongside my SMEs while relying on academic research and tech news to fill in the blanks. I ventured lots of guesses about how embedding, tokenization, or various models might work, and those guesses were often inelegant at best. My SMEs were patient and ran the gamut of all possible tech roles: software architects, PMs, field folks, engineers, designers, you name it.\nAll of this, and I still needed to understand what our feature did and who our audience was.\nThe doc I’ve provided is an introduction doc that covers a mix of observability and AI concepts. Despite my reservations about AI, this project was a labor of love! I recommend exploring the entire area for all of the docs work I did in a few months.\nGoing deep with SREs\rEven though Company offered some infrastructure solutions, they’re primarily known as being app monitoring-forward. As an associate writer, I didn’t fully appreciate what this meant or how a docs site might expose a product’s strengths and weaknesses.","learning-about-genai#Learning about genAI":"","untangling-the-aws-story#Untangling the AWS story":""},"title":"Portfolio notes~"},"/resume/":{"data":{"":"\rPrevious\rNext    \r/ [pdf]\rView the PDF file here."},"title":"resume"}}